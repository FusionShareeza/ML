{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNN Linus Etemi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = 'CPU'\n",
    "\n",
    "if TYPE == 'CPU':\n",
    "    import numpy as np\n",
    "else:\n",
    "    import cupy as np\n",
    "    \n",
    "import scipy.special\n",
    "import math\n",
    "import matplotlib\n",
    "from ray import tune\n",
    "from csv import writer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data_file = open(\"./MNISTData_red/mnist_train_red_8_9_by_90P.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "test_data_file = open(\"./mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "hiddennodes_start = 800\n",
    "hiddennodes_stop = 800\n",
    "hiddennodes_step = 100\n",
    "\n",
    "learningrate_start = 0.08\n",
    "learningrate_stop = 0.08\n",
    "learningrate_step = 0.01\n",
    "\n",
    "epochs_start = 1\n",
    "epochs_stop = 2\n",
    "epochs_step = 0\n",
    "\n",
    "outputnodes = 10\n",
    "hiddennodes=800\n",
    "learningrate=0.08\n",
    "epochs=5\n",
    "\n",
    "label_min = 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronales Netz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "    def __init__(self, innodes, outnodes, hidnodes, learningrate, epochs, network_number):\n",
    "        self.inodes = innodes\n",
    "        self.onodes = outnodes\n",
    "        self.hnodes = hidnodes\n",
    "        self.lr = learningrate\n",
    "        self.epo = epochs\n",
    "        self.net = network_number\n",
    "        self.wih = ((np.random.rand(self.hnodes,self.inodes)*2)-1)\n",
    "        self.who = ((np.random.rand(self.onodes,self.hnodes)*2)-1)\n",
    "        \n",
    "    def activation_function(self, z):\n",
    "        return 1/(1+ np.exp(-z))\n",
    "\n",
    "        pass\n",
    "\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors = np.dot(self.who.T, output_errors) \n",
    "        self.who += self.lr * np.dot( (output_errors*final_outputs*(1.0-final_outputs)), np.transpose(hidden_outputs)) \n",
    "        self.wih += self.lr * np.dot( (hidden_errors*hidden_outputs*(1.0-hidden_outputs)), np.transpose(inputs)) \n",
    "        \n",
    "        pass\n",
    "\n",
    "    def query(self, input_list):\n",
    "        inputs = np.array(input_list, ndmin=2).T\n",
    "        \n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    \n",
    "    def test_train(self):  \n",
    "        if(self.net == 1):\n",
    "            training_data_file = open(\"./MNISTData_red/mnist_train_red_8_9_by_90P.csv\", 'r')\n",
    "            training_data_list = training_data_file.readlines()\n",
    "            training_data_file.close()\n",
    "        elif(self.net == 2):\n",
    "            training_data_file = open(\"./mnist_second_train.csv\", 'r')\n",
    "            training_data_list = training_data_file.readlines()\n",
    "            training_data_file.close()\n",
    "\n",
    "        for e in range(self.epo):\n",
    "            for record in training_data_list:\n",
    "\n",
    "                all_values = record.split(',')\n",
    "\n",
    "                inputs = (np.asarray(all_values[1:], dtype=np.float64) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "                targets = np.zeros(outputnodes) + 0.01\n",
    "                targets[int(all_values[0])] = 0.99\n",
    "                self.train(inputs, targets)\n",
    "                pass\n",
    "            pass\n",
    "\n",
    "        scorecard = []\n",
    "        save = []\n",
    "\n",
    "        for record in test_data_list:\n",
    "            all_values = record.split(',')\n",
    "            correct_label = int(all_values[0])\n",
    "            inputs = (np.asarray(all_values[1:], dtype=np.float64) / 255.0 * 0.99) + 0.01\n",
    "            outputs = self.query(inputs)\n",
    "            label = np.argmax(outputs)\n",
    "\n",
    "            if(label >= label_min):\n",
    "                \n",
    "                scorecard.append(1)\n",
    "            else:\n",
    "\n",
    "                scorecard.append(0)\n",
    "                if(self.net == 1):\n",
    "                    save.append(list(map(int, all_values)))\n",
    "                else:\n",
    "                    pass\n",
    "                pass\n",
    "            \n",
    "\n",
    "            scorecard_array = np.asarray(scorecard)\n",
    "            performance = scorecard_array.sum() / scorecard_array.size\n",
    "        \n",
    "        if(self.net == 1):\n",
    "            np.savetxt('mnist_second_train.csv', save, fmt='%d', delimiter=',')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        return performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Writer und Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_list_as_row(list_of_elem):\n",
    "    with open('Results.csv', 'a+', newline='') as write_obj:\n",
    "        csv_writer = writer(write_obj)\n",
    "        csv_writer.writerow(list_of_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learningrate_i = learningrate_start\n",
    "#hiddennodes_i = hiddennodes_start\n",
    "#epochs_i = epochs_start\n",
    "\n",
    "\n",
    "#while epochs_i <= epochs_stop:\n",
    "#    while hiddennodes_i <= hiddennodes_stop:\n",
    "#        while learningrate_i <= learningrate_stop:\n",
    "#            intermediate_score = neuralNetwork(784,10,hiddennodes_i,learningrate_i,epochs_i).test_train()\n",
    "#            print('Epoch [{:02d}/{:02d}]     | Hidden_Nodes [{:04d}/{:04d}]     | Learning_Rate [{:.2f}/{:.2f}]     | Performance: {:.5f}'.format(epochs_i,epochs_stop,hiddennodes_i,hiddennodes_stop,learningrate_i,learningrate_stop,intermediate_score))\n",
    "#            append_list_as_row([784,10,hiddennodes_i,learningrate_i,epochs_i,intermediate_score])\n",
    "#            learningrate_i += learningrate_step \n",
    "#        learningrate_i = learningrate_start    \n",
    "#        hiddennodes_i += hiddennodes_step\n",
    "#        print(\"========================================================\")\n",
    "#    hiddennodes_i = hiddennodes_start\n",
    "#    epochs_i += epochs_step\n",
    "#    print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring und Aufruf von Beiden Netzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8951\n",
      "0.5243\n"
     ]
    }
   ],
   "source": [
    "\n",
    "network_number=1\n",
    "intermediate_score = neuralNetwork(784,10,hiddennodes,learningrate,epochs,network_number).test_train()\n",
    "print(intermediate_score)\n",
    "\n",
    "network_number=2\n",
    "intermediate_score = neuralNetwork(784,10,hiddennodes,learningrate,epochs,network_number).test_train()\n",
    "print(intermediate_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
