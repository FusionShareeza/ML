{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNN Linus Etemi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = 'GPU'\n",
    "\n",
    "if TYPE == 'CPU':\n",
    "    import numpy as np\n",
    "else:\n",
    "    import cupy as np\n",
    "    \n",
    "import scipy.special\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "import pickle\n",
    "\n",
    "from ray import tune\n",
    "from csv import writer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hiddennodes_start = 800\n",
    "#hiddennodes_stop = 800\n",
    "#hiddennodes_step = 100\n",
    "\n",
    "#learningrate_start = 0.08\n",
    "#learningrate_stop = 0.08\n",
    "#learningrate_step = 0.01\n",
    "\n",
    "#epochs_start = 1\n",
    "#epochs_stop = 2\n",
    "#epochs_step = 0\n",
    "\n",
    "outputnodes = 10\n",
    "hiddennodes = 900\n",
    "learningrate = 0.05\n",
    "inputnodes = 784\n",
    "epochs= 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronales Netz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "    def __init__(self, innodes, outnodes, hidnodes, learningrate, epochs):\n",
    "        self.inodes = innodes\n",
    "        self.onodes = outnodes\n",
    "        self.hnodes = hidnodes\n",
    "        self.lr = learningrate\n",
    "        self.epo = epochs\n",
    "        self.wih = ((np.random.rand(self.hnodes,self.inodes)*2)-1)\n",
    "        self.who = ((np.random.rand(self.onodes,self.hnodes)*2)-1)\n",
    "        pass\n",
    "    \n",
    "    def activation_function(self, z: int) -> classmethod:\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors = np.dot(self.who.T, output_errors) \n",
    "        self.who += self.lr * np.dot( (output_errors*final_outputs*(1.0-final_outputs)), np.transpose(hidden_outputs)) \n",
    "        self.wih += self.lr * np.dot( (hidden_errors*hidden_outputs*(1.0-hidden_outputs)), np.transpose(inputs)) \n",
    "        pass\n",
    "\n",
    "    def query(self, input_list):\n",
    "        inputs = np.array(input_list, ndmin=2).T\n",
    "        \n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_content(fname: str) -> None:\n",
    "    file = open(fname, \"w+\")\n",
    "    file.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(n, net, epo):  \n",
    "\n",
    "        clear_content('mnist_second_train.csv')\n",
    "        training_data_file = open(\"./MNISTData_red/mnist_train_red_8_9_by_90P.csv\", 'r')\n",
    "        training_data_list = training_data_file.readlines()\n",
    "        training_data_file.close()\n",
    "\n",
    "        for e in range(epo):\n",
    "            for record in training_data_list:\n",
    "                all_values = record.split(',')\n",
    "\n",
    "                inputs = (np.asarray(all_values[1:], dtype=np.float64) / 255.0 * 0.99) + 0.01\n",
    "                targets = np.zeros(outputnodes) + 0.01\n",
    "                targets[int(all_values[0])] = 0.99\n",
    "                n.train(inputs, targets)\n",
    "\n",
    "                pass\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_Network 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_network(n, net, epo):  \n",
    "#         if(net == 1):\n",
    "#             n.clear_content('mnist_second_train.csv')\n",
    "#             training_data_file = open(\"./MNISTData_red/mnist_train_red_8_9_by_90P.csv\", 'r')\n",
    "#             training_data_list = training_data_file.readlines()\n",
    "#             training_data_file.close()\n",
    "#         elif(net == 2):\n",
    "#             training_data_file = open(\"./mnist_second_train.csv\", 'r')\n",
    "#             training_data_list = training_data_file.readlines()\n",
    "#             training_data_file.close()\n",
    "#         for e in range(epo):\n",
    "#             for record in training_data_list:\n",
    "#                 all_values = record.split(',')\n",
    "\n",
    "#                 inputs = (np.asarray(all_values[1:], dtype=np.float64) / 255.0 * 0.99) + 0.01\n",
    "#                 targets = np.zeros(outputnodes) + 0.01\n",
    "#                 targets[int(all_values[0])] = 0.99\n",
    "#                 n.train(inputs, targets)\n",
    "\n",
    "#                 pass\n",
    "#             pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(n):\n",
    "\n",
    "    test_data_file = open(\"./MNISTData_red/mnist_train_red_8_9_by_90P.csv\", 'r')\n",
    "    test_data_list = test_data_file.readlines()\n",
    "    test_data_file.close()\n",
    "    array_data_all = []\n",
    "    scorecard_p = []    \n",
    "    scorecard_q = []\n",
    "\n",
    "    for i in range(100):\n",
    "        array_data_all.append([])\n",
    "        scorecard_p.append([])\n",
    "        scorecard_q.append([])\n",
    "\n",
    "    for record in test_data_list:\n",
    "        all_values = record.split(',')\n",
    "        correct_label = int(all_values[0])\n",
    "        inputs = (np.asarray(all_values[1:], dtype=np.float64) / 255.0 * 0.99) + 0.01\n",
    "        outputs = n.query(inputs)\n",
    "        label_max = outputs[np.argmax(outputs)]\n",
    "        label = np.argmax(outputs)\n",
    "\n",
    "        for threshold in range(100):\n",
    "            if(label_max > (threshold/100)):\n",
    "                scorecard_p[threshold].append(1)\n",
    "                if(label == correct_label):\n",
    "                    scorecard_q[threshold].append(1)\n",
    "                else:\n",
    "                    scorecard_q[threshold].append(0)\n",
    "            else:\n",
    "                scorecard_p[threshold].append(0)\n",
    "                #zweite netz werte \n",
    "\n",
    "    for i in range(100):\n",
    "        scorecard_p_array = np.asarray(scorecard_p[i])\n",
    "        scorecard_q_array = np.asarray(scorecard_q[i])\n",
    "\n",
    "        array_data_all[i].append('T: {}'.format(i/100))\n",
    "        array_data_all[i].append('P: {:.5f}'.format(scorecard_p_array.sum()/scorecard_p_array.size))\n",
    "        array_data_all[i].append('Q: {:.5f}'.format(scorecard_q_array.sum()/scorecard_q_array.size))\n",
    "\n",
    "\n",
    "    return array_data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def test_network2(n):\n",
    "    # test_data_file = open(\"./mnist_accepted.csv\", 'r')\n",
    "    # test_data_list = test_data_file.readlines()\n",
    "    # test_data_file.close()\n",
    "\n",
    "    # scorecard_train = []\n",
    "\n",
    "    # for record in test_data_list:\n",
    "\n",
    "    #         all_values = record.split(',')\n",
    "    #         correct_label = int(all_values[0])\n",
    "    #         inputs = (np.asarray(all_values[1:], dtype=np.float64) / 255.0 * 0.99) + 0.01\n",
    "    #         outputs = n.query(inputs)\n",
    "    #         score = outputs[np.argmax(outputs)]\n",
    "\n",
    "    #         if(np.argmax(outputs) == correct_label):\n",
    "    #             scorecard_train.append(1)\n",
    "    #         else:\n",
    "    #             scorecard_train.append(0)\n",
    "    #             append_list_as_row('mnist_second_train.csv', list(map(int, all_values)))\n",
    "                    \n",
    "\n",
    "\n",
    "    # scorecard_train_array = np.asarray(scorecard_train)\n",
    "    # performance2 = scorecard_train_array.sum() / scorecard_train_array.size\n",
    "\n",
    "    # return performance2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Writer und Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_list_as_row(fname,list_of_elem):\n",
    "    with open(fname, 'a+', newline='') as write_obj:\n",
    "        csv_writer = writer(write_obj)\n",
    "        csv_writer.writerow(list_of_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learningrate_i = learningrate_start\n",
    "#hiddennodes_i = hiddennodes_start\n",
    "#epochs_i = epochs_start\n",
    "\n",
    "\n",
    "#while epochs_i <= epochs_stop:\n",
    "#    while hiddennodes_i <= hiddennodes_stop:\n",
    "#        while learningrate_i <= learningrate_stop:\n",
    "#            intermediate_score = neuralNetwork(784,10,hiddennodes_i,learningrate_i,epochs_i).test_train()\n",
    "#            print('Epoch [{:02d}/{:02d}]     | Hidden_Nodes [{:04d}/{:04d}]     | Learning_Rate [{:.2f}/{:.2f}]     | Performance: {:.5f}'.format(epochs_i,epochs_stop,hiddennodes_i,hiddennodes_stop,learningrate_i,learningrate_stop,intermediate_score))\n",
    "#            append_list_as_row([784,10,hiddennodes_i,learningrate_i,epochs_i,intermediate_score])\n",
    "#            learningrate_i += learningrate_step \n",
    "#        learningrate_i = learningrate_start    \n",
    "#        hiddennodes_i += hiddennodes_step\n",
    "#        print(\"========================================================\")\n",
    "#    hiddennodes_i = hiddennodes_start\n",
    "#    epochs_i += epochs_step\n",
    "#    print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring und Aufruf von Beiden Netzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['T: 0.0', 'P: 1.00000', 'Q: 0.95761'], ['T: 0.01', 'P: 0.99988', 'Q: 0.95760'], ['T: 0.02', 'P: 0.99974', 'Q: 0.95770'], ['T: 0.03', 'P: 0.99953', 'Q: 0.95785'], ['T: 0.04', 'P: 0.99921', 'Q: 0.95802'], ['T: 0.05', 'P: 0.99893', 'Q: 0.95825'], ['T: 0.06', 'P: 0.99842', 'Q: 0.95855'], ['T: 0.07', 'P: 0.99781', 'Q: 0.95889'], ['T: 0.08', 'P: 0.99714', 'Q: 0.95911'], ['T: 0.09', 'P: 0.99611', 'Q: 0.95970'], ['T: 0.1', 'P: 0.99530', 'Q: 0.96013'], ['T: 0.11', 'P: 0.99427', 'Q: 0.96066'], ['T: 0.12', 'P: 0.99336', 'Q: 0.96114'], ['T: 0.13', 'P: 0.99226', 'Q: 0.96177'], ['T: 0.14', 'P: 0.99099', 'Q: 0.96221'], ['T: 0.15', 'P: 0.98977', 'Q: 0.96269'], ['T: 0.16', 'P: 0.98831', 'Q: 0.96338'], ['T: 0.17', 'P: 0.98726', 'Q: 0.96397'], ['T: 0.18', 'P: 0.98590', 'Q: 0.96456'], ['T: 0.19', 'P: 0.98448', 'Q: 0.96531'], ['T: 0.2', 'P: 0.98345', 'Q: 0.96585'], ['T: 0.21', 'P: 0.98209', 'Q: 0.96649'], ['T: 0.22', 'P: 0.98074', 'Q: 0.96704'], ['T: 0.23', 'P: 0.97924', 'Q: 0.96755'], ['T: 0.24', 'P: 0.97786', 'Q: 0.96802'], ['T: 0.25', 'P: 0.97646', 'Q: 0.96849'], ['T: 0.26', 'P: 0.97517', 'Q: 0.96922'], ['T: 0.27', 'P: 0.97340', 'Q: 0.97001'], ['T: 0.28', 'P: 0.97205', 'Q: 0.97049'], ['T: 0.29', 'P: 0.97057', 'Q: 0.97099'], ['T: 0.3', 'P: 0.96895', 'Q: 0.97155'], ['T: 0.31', 'P: 0.96737', 'Q: 0.97217'], ['T: 0.32', 'P: 0.96551', 'Q: 0.97279'], ['T: 0.33', 'P: 0.96395', 'Q: 0.97331'], ['T: 0.34', 'P: 0.96257', 'Q: 0.97380'], ['T: 0.35', 'P: 0.96095', 'Q: 0.97420'], ['T: 0.36', 'P: 0.95973', 'Q: 0.97451'], ['T: 0.37', 'P: 0.95789', 'Q: 0.97520'], ['T: 0.38', 'P: 0.95637', 'Q: 0.97560'], ['T: 0.39', 'P: 0.95453', 'Q: 0.97623'], ['T: 0.4', 'P: 0.95274', 'Q: 0.97691'], ['T: 0.41', 'P: 0.95118', 'Q: 0.97736'], ['T: 0.42', 'P: 0.94940', 'Q: 0.97790'], ['T: 0.43', 'P: 0.94770', 'Q: 0.97846'], ['T: 0.44', 'P: 0.94612', 'Q: 0.97889'], ['T: 0.45', 'P: 0.94424', 'Q: 0.97936'], ['T: 0.46', 'P: 0.94266', 'Q: 0.97980'], ['T: 0.47', 'P: 0.94098', 'Q: 0.98009'], ['T: 0.48', 'P: 0.93911', 'Q: 0.98052'], ['T: 0.49', 'P: 0.93707', 'Q: 0.98096'], ['T: 0.5', 'P: 0.93541', 'Q: 0.98149'], ['T: 0.51', 'P: 0.93403', 'Q: 0.98178'], ['T: 0.52', 'P: 0.93235', 'Q: 0.98219'], ['T: 0.53', 'P: 0.93046', 'Q: 0.98258'], ['T: 0.54', 'P: 0.92836', 'Q: 0.98309'], ['T: 0.55', 'P: 0.92627', 'Q: 0.98356'], ['T: 0.56', 'P: 0.92380', 'Q: 0.98415'], ['T: 0.57', 'P: 0.92165', 'Q: 0.98459'], ['T: 0.58', 'P: 0.91951', 'Q: 0.98509'], ['T: 0.59', 'P: 0.91710', 'Q: 0.98553'], ['T: 0.6', 'P: 0.91507', 'Q: 0.98597'], ['T: 0.61', 'P: 0.91292', 'Q: 0.98640'], ['T: 0.62', 'P: 0.91035', 'Q: 0.98667'], ['T: 0.63', 'P: 0.90804', 'Q: 0.98706'], ['T: 0.64', 'P: 0.90583', 'Q: 0.98741'], ['T: 0.65', 'P: 0.90340', 'Q: 0.98765'], ['T: 0.66', 'P: 0.90051', 'Q: 0.98824'], ['T: 0.67', 'P: 0.89767', 'Q: 0.98863'], ['T: 0.68', 'P: 0.89498', 'Q: 0.98898'], ['T: 0.69', 'P: 0.89236', 'Q: 0.98945'], ['T: 0.7', 'P: 0.88955', 'Q: 0.98978'], ['T: 0.71', 'P: 0.88613', 'Q: 0.99022'], ['T: 0.72', 'P: 0.88343', 'Q: 0.99042'], ['T: 0.73', 'P: 0.88005', 'Q: 0.99102'], ['T: 0.74', 'P: 0.87661', 'Q: 0.99140'], ['T: 0.75', 'P: 0.87257', 'Q: 0.99192'], ['T: 0.76', 'P: 0.86885', 'Q: 0.99231'], ['T: 0.77', 'P: 0.86522', 'Q: 0.99256'], ['T: 0.78', 'P: 0.86156', 'Q: 0.99295'], ['T: 0.79', 'P: 0.85759', 'Q: 0.99320'], ['T: 0.8', 'P: 0.85339', 'Q: 0.99343'], ['T: 0.81', 'P: 0.84869', 'Q: 0.99382'], ['T: 0.82', 'P: 0.84343', 'Q: 0.99404'], ['T: 0.83', 'P: 0.83814', 'Q: 0.99439'], ['T: 0.84', 'P: 0.83247', 'Q: 0.99470'], ['T: 0.85', 'P: 0.82605', 'Q: 0.99500'], ['T: 0.86', 'P: 0.81985', 'Q: 0.99521'], ['T: 0.87', 'P: 0.81217', 'Q: 0.99556'], ['T: 0.88', 'P: 0.80425', 'Q: 0.99579'], ['T: 0.89', 'P: 0.79502', 'Q: 0.99608'], ['T: 0.9', 'P: 0.78418', 'Q: 0.99641'], ['T: 0.91', 'P: 0.77219', 'Q: 0.99669'], ['T: 0.92', 'P: 0.75919', 'Q: 0.99704'], ['T: 0.93', 'P: 0.74367', 'Q: 0.99733'], ['T: 0.94', 'P: 0.72481', 'Q: 0.99779'], ['T: 0.95', 'P: 0.70221', 'Q: 0.99801'], ['T: 0.96', 'P: 0.67063', 'Q: 0.99807'], ['T: 0.97', 'P: 0.62609', 'Q: 0.99880'], ['T: 0.98', 'P: 0.55919', 'Q: 0.99902'], ['T: 0.99', 'P: 0.42242', 'Q: 0.99947']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n1 = neuralNetwork(784,10,hiddennodes,learningrate,epochs)\n",
    "#train_network(n1, network_number, epochs)\n",
    "#pickle.dump(n1, open('neural_network_1.obj', 'wb'))\n",
    "n1 = pickle.load(open('neural_network_1.obj', 'rb'))\n",
    "\n",
    "intermediate_score1 = test_network(n1)\n",
    "print(intermediate_score1)\n",
    "\n",
    "\n",
    "# network_number=2\n",
    "# n2 = neuralNetwork(784,10,hiddennodes,learningrate,epochs)\n",
    "# train_network(n2, network_number, epochs)\n",
    "# intermediate_score2 = test_network(n2, network_number)\n",
    "# print(intermediate_score2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
